╔══════════════════════════════════════════════════════════════════════════════╗
║              OLLAMA TO MLX CONVERSION SYSTEM - QUICK REFERENCE               ║
╚══════════════════════════════════════════════════════════════════════════════╝

┌──────────────────────────────────────────────────────────────────────────────┐
│ THREE-STEP MIGRATION                                                         │
└──────────────────────────────────────────────────────────────────────────────┘

  1. python3 ollama-model-analysis.py       # See what will happen
  2. ./convert-ollama-to-mlx.sh --dry-run   # Preview safely
  3. ./convert-ollama-to-mlx.sh             # Execute migration

┌──────────────────────────────────────────────────────────────────────────────┐
│ QUICK COMMANDS                                                               │
└──────────────────────────────────────────────────────────────────────────────┘

  Analysis:
    python3 ollama-model-analysis.py           # Full report
    python3 ollama-model-analysis.py --json    # JSON output
    python3 ollama-model-analysis.py --summary # Brief summary

  Migration (Interactive):
    ./convert-ollama-to-mlx.sh --dry-run       # Preview only
    ./convert-ollama-to-mlx.sh                 # With confirmations
    ./convert-ollama-to-mlx.sh --auto          # No confirmations

  Migration (Automated):
    ./migrate-to-mlx.sh --dry-run              # Preview only
    ./migrate-to-mlx.sh --execute              # Full migration
    ./migrate-to-mlx.sh --execute --delete-only    # Delete Ollama only
    ./migrate-to-mlx.sh --execute --download-only  # Download MLX only
    ./migrate-to-mlx.sh --verify-only          # Check status

  After Migration:
    source mlx/venv/bin/activate               # Activate MLX
    mlx_lm.chat --model mlx-community/Qwen2.5-Coder-7B-Instruct-4bit

┌──────────────────────────────────────────────────────────────────────────────┐
│ WHAT GETS MIGRATED                                                           │
└──────────────────────────────────────────────────────────────────────────────┘

  DELETE (7 models, 105GB freed):
    • qwen-coder-32b-uncensored (19GB)  → Qwen2.5-Coder-32B MLX
    • deepseek-r1-32b-uncensored (19GB) → DeepSeek-R1-8B MLX (4x smaller!)
    • qwen2.5-survival (19GB)           → Qwen2.5-Coder-7B MLX
    • qwen2.5-undercover (19GB)         → Qwen2.5-Coder-7B MLX
    • qwen2.5-uncensored (19GB)         → Qwen2.5-Coder-7B MLX
    • nous-hermes2 (6.1GB)              → Qwen3-7B MLX
    • dolphin-mistral (4.1GB)           → Mistral-7B MLX

  CONVERT (2 models):
    • qwen2.5-max (9GB)                 → Qwen3-14B MLX (2x faster)
    • qwen2.5:14b (9GB)                 → Qwen3-14B MLX (2x faster)

  KEEP (2 models):
    • llama3.1:8b (4.9GB)               - Fallback
    • gemma2:2b (1.6GB)                 - Ultra-light

┌──────────────────────────────────────────────────────────────────────────────┐
│ PERFORMANCE GAINS                                                            │
└──────────────────────────────────────────────────────────────────────────────┘

  Qwen2.5-Coder-7B:  20-30 tok/s → 60-80 tok/s  (+200-300%)
  DeepSeek-R1-8B:    10-15 tok/s → 50-70 tok/s  (+400-600%)
  Qwen3-14B:         20-30 tok/s → 40-60 tok/s  (+100-200%)
  Mistral-7B:        15-25 tok/s → 70-100 tok/s (+300-500%)

  Space: 130GB → 65GB (69GB freed!)

┌──────────────────────────────────────────────────────────────────────────────┐
│ MLX MODELS USAGE                                                             │
└──────────────────────────────────────────────────────────────────────────────┘

  Fast Coding (60-80 tok/s):
    mlx_lm.chat --model mlx-community/Qwen2.5-Coder-7B-Instruct-4bit

  General Questions (40-60 tok/s):
    mlx_lm.chat --model mlx-community/Qwen3-14B-Instruct-4bit

  Math & Reasoning (50-70 tok/s):
    mlx_lm.chat --model mlx-community/DeepSeek-R1-Distill-Llama-8B

  Ultra-Fast (70-100 tok/s):
    mlx_lm.chat --model mlx-community/Mistral-7B-Instruct-v0.3-4bit

  Complex Coding (11-22 tok/s, needs 32GB RAM):
    mlx_lm.chat --model mlx-community/Qwen2.5-Coder-32B-Instruct-4bit

┌──────────────────────────────────────────────────────────────────────────────┐
│ TROUBLESHOOTING                                                              │
└──────────────────────────────────────────────────────────────────────────────┘

  "ollama not found":
    brew install ollama && ollama serve

  "jq not found":
    brew install jq

  "Insufficient space":
    ./migrate-to-mlx.sh --execute --delete-only  # Free space first

  Check logs:
    tail -f $(ls -t *.log | head -1)

  Verify status:
    ./migrate-to-mlx.sh --verify-only

┌──────────────────────────────────────────────────────────────────────────────┐
│ FILES CREATED                                                                │
└──────────────────────────────────────────────────────────────────────────────┘

  Core:
    mlx-model-mapping.json           # Master configuration
    ollama-model-analysis.py         # Analysis tool
    convert-ollama-to-mlx.sh         # Interactive migration
    migrate-to-mlx.sh                # Automated migration

  Documentation:
    OLLAMA-TO-MLX-CONVERSION.md      # Full guide (read this first!)
    README-CONVERSION-SYSTEM.md      # Quick reference
    QUICK-START-MLX.md               # Daily use commands
    CONVERSION-SYSTEM-SUMMARY.md     # System overview
    CONVERSION-QUICKREF.txt          # This file

  Generated:
    conversion-*.log                 # Logs
    migration-*.log                  # Logs
    .ollama-backups/                 # Backups

┌──────────────────────────────────────────────────────────────────────────────┐
│ GETTING HELP                                                                 │
└──────────────────────────────────────────────────────────────────────────────┘

  Script Help:
    ./convert-ollama-to-mlx.sh --help
    ./migrate-to-mlx.sh --help
    python3 ollama-model-analysis.py --help

  Documentation:
    cat OLLAMA-TO-MLX-CONVERSION.md      # Comprehensive guide
    cat QUICK-START-MLX.md               # Quick commands
    cat README-CONVERSION-SYSTEM.md      # Overview

┌──────────────────────────────────────────────────────────────────────────────┐
│ SAFETY FEATURES                                                              │
└──────────────────────────────────────────────────────────────────────────────┘

  ✓ Automatic backups before any deletions
  ✓ Dry-run mode to preview changes safely
  ✓ Pre-flight checks for requirements
  ✓ Detailed logging for audit trail
  ✓ State tracking for resume capability
  ✓ Verification commands to check status
  ✓ Rollback instructions in case of issues

╔══════════════════════════════════════════════════════════════════════════════╗
║                          READY TO START!                                     ║
║                                                                              ║
║  python3 ollama-model-analysis.py                                           ║
║  ./convert-ollama-to-mlx.sh --dry-run                                       ║
║  ./convert-ollama-to-mlx.sh                                                 ║
╚══════════════════════════════════════════════════════════════════════════════╝
