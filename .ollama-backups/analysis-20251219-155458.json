{
  "timestamp": "2025-12-19T15:54:58.446064",
  "total_models": 12,
  "categorized": {
    "DELETE": [
      {
        "name": "qwen-coder-32b-uncensored:latest",
        "id": "00606d710f57",
        "size_gb": 19.0,
        "size_str": "19 GB",
        "modified": "5 weeks ago",
        "action": "DELETE",
        "reason": "Redundant variant - replace with Qwen2.5-Coder-32B MLX",
        "replacement": "qwen25-coder-32b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/qwen25-coder-32b",
          "size_gb": 18,
          "huggingface_repo": "mlx-community/Qwen2.5-Coder-32B-Instruct-4bit",
          "use_case": "Complex coding, architecture (11-22 tok/sec), requires 32GB+ RAM",
          "replaces": [
            "qwen-coder-32b-uncensored:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen2.5-Coder-32B-Instruct-4bit",
          "speed_tokens_per_sec": "11-22"
        }
      },
      {
        "name": "deepseek-r1-32b-uncensored:latest",
        "id": "9c6ce7315719",
        "size_gb": 19.0,
        "size_str": "19 GB",
        "modified": "5 weeks ago",
        "action": "DELETE",
        "reason": "Replace with DeepSeek-R1-8B MLX (4x smaller, 2x faster, same capability)",
        "replacement": "deepseek-r1-8b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/deepseek-r1-8b",
          "size_gb": 4.5,
          "huggingface_repo": "mlx-community/DeepSeek-R1-Distill-Llama-8B",
          "use_case": "Math, reasoning, problem-solving (50-70 tok/sec), 4x smaller than 32B",
          "replaces": [
            "deepseek-r1-32b-uncensored:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/DeepSeek-R1-Distill-Llama-8B",
          "speed_tokens_per_sec": "50-70"
        }
      },
      {
        "name": "qwen2.5-survival:latest",
        "id": "ce2ff4130f7b",
        "size_gb": 19.0,
        "size_str": "19 GB",
        "modified": "5 weeks ago",
        "action": "DELETE",
        "reason": "Redundant variant - not needed",
        "replacement": "qwen25-coder-7b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/qwen25-coder-7b",
          "size_gb": 4.5,
          "huggingface_repo": "mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "use_case": "Fast coding (60-80 tok/sec), daily code fixes",
          "replaces": [
            "qwen2.5-survival:latest",
            "qwen2.5-undercover:latest",
            "qwen2.5-uncensored:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "speed_tokens_per_sec": "60-80"
        }
      },
      {
        "name": "qwen2.5-undercover:latest",
        "id": "ddc099575c05",
        "size_gb": 19.0,
        "size_str": "19 GB",
        "modified": "5 weeks ago",
        "action": "DELETE",
        "reason": "Redundant variant - not needed",
        "replacement": "qwen25-coder-7b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/qwen25-coder-7b",
          "size_gb": 4.5,
          "huggingface_repo": "mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "use_case": "Fast coding (60-80 tok/sec), daily code fixes",
          "replaces": [
            "qwen2.5-survival:latest",
            "qwen2.5-undercover:latest",
            "qwen2.5-uncensored:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "speed_tokens_per_sec": "60-80"
        }
      },
      {
        "name": "qwen2.5-uncensored:latest",
        "id": "f3a7b2358e08",
        "size_gb": 19.0,
        "size_str": "19 GB",
        "modified": "5 weeks ago",
        "action": "DELETE",
        "reason": "Redundant variant - not needed",
        "replacement": "qwen25-coder-7b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/qwen25-coder-7b",
          "size_gb": 4.5,
          "huggingface_repo": "mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "use_case": "Fast coding (60-80 tok/sec), daily code fixes",
          "replaces": [
            "qwen2.5-survival:latest",
            "qwen2.5-undercover:latest",
            "qwen2.5-uncensored:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "speed_tokens_per_sec": "60-80"
        }
      },
      {
        "name": "dolphin-mistral:latest",
        "id": "5dc8c5a2be65",
        "size_gb": 4.1,
        "size_str": "4.1 GB",
        "modified": "5 weeks ago",
        "action": "DELETE",
        "reason": "Replace with Dolphin 3.0 MLX or Mistral-7B MLX",
        "replacement": "mistral-7b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/mistral-7b",
          "size_gb": 4,
          "huggingface_repo": "mlx-community/Mistral-7B-Instruct-v0.3-4bit",
          "use_case": "Ultra-fast general use (70-100 tok/sec)",
          "replaces": [
            "dolphin-mistral:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/Mistral-7B-Instruct-v0.3-4bit",
          "speed_tokens_per_sec": "70-100"
        }
      },
      {
        "name": "nous-hermes2:latest",
        "id": "d50977d0b36a",
        "size_gb": 6.1,
        "size_str": "6.1 GB",
        "modified": "7 weeks ago",
        "action": "DELETE",
        "reason": "Outdated model",
        "replacement": "qwen3-7b",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/qwen3-7b",
          "size_gb": 4.5,
          "huggingface_repo": "mlx-community/Qwen3-7B-Instruct-4bit",
          "use_case": "Lightweight general use, faster than phi3:mini",
          "replaces": [
            "nous-hermes2:latest"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen3-7B-Instruct-4bit",
          "speed_tokens_per_sec": "60-80"
        }
      }
    ],
    "CONVERT": [
      {
        "name": "qwen2.5-max:latest",
        "id": "04546adb184a",
        "size_gb": 9.0,
        "size_str": "9.0 GB",
        "modified": "5 weeks ago",
        "action": "CONVERT",
        "reason": "Good model, but MLX version will be 2-3x faster",
        "replacement": "qwen3-14b",
        "mlx_info": {
          "status": "PENDING",
          "local_path": "mlx/qwen3-14b",
          "size_gb": 9,
          "huggingface_repo": "mlx-community/Qwen3-14B-Instruct-4bit",
          "use_case": "General questions, research, balanced (40-60 tok/sec)",
          "replaces": [
            "qwen2.5-max:latest",
            "qwen2.5:14b"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen3-14B-Instruct-4bit",
          "speed_tokens_per_sec": "40-60"
        }
      },
      {
        "name": "qwen2.5:14b",
        "id": "7cdf5a0187d5",
        "size_gb": 9.0,
        "size_str": "9.0 GB",
        "modified": "5 weeks ago",
        "action": "CONVERT",
        "reason": "Good model, but MLX version will be 2-3x faster",
        "replacement": "qwen3-14b",
        "mlx_info": {
          "status": "PENDING",
          "local_path": "mlx/qwen3-14b",
          "size_gb": 9,
          "huggingface_repo": "mlx-community/Qwen3-14B-Instruct-4bit",
          "use_case": "General questions, research, balanced (40-60 tok/sec)",
          "replaces": [
            "qwen2.5-max:latest",
            "qwen2.5:14b"
          ],
          "command": "mlx_lm.chat --model mlx-community/Qwen3-14B-Instruct-4bit",
          "speed_tokens_per_sec": "40-60"
        }
      }
    ],
    "KEEP": [
      {
        "name": "gemma2:2b",
        "id": "8ccf136fdd52",
        "size_gb": 1.6,
        "size_str": "1.6 GB",
        "modified": "5 weeks ago",
        "action": "KEEP",
        "reason": "Edge cases only, can delete when MLX models ready",
        "replacement": null,
        "mlx_info": null
      },
      {
        "name": "llama3.1:8b",
        "id": "46e0c10c039e",
        "size_gb": 4.9,
        "size_str": "4.9 GB",
        "modified": "5 weeks ago",
        "action": "KEEP",
        "reason": "Keep as fallback, or replace with Dolphin-3.0-Llama3.1-8B MLX",
        "replacement": null,
        "mlx_info": null
      }
    ],
    "OPTIONAL_CONVERT": [
      {
        "name": "phi3:mini",
        "id": "4f2222927938",
        "size_gb": 2.2,
        "size_str": "2.2 GB",
        "modified": "5 weeks ago",
        "action": "OPTIONAL_CONVERT",
        "reason": "Ultra-lightweight, keep for now or replace with Phi-4-14B MLX",
        "replacement": "phi-4",
        "mlx_info": {
          "status": "DOWNLOADED",
          "local_path": "mlx/phi-4",
          "size_gb": 9,
          "huggingface_repo": "mlx-community/phi-4-4bit",
          "use_case": "Math/STEM specialist",
          "replaces": [
            "phi3:mini"
          ],
          "command": "mlx_lm.chat --model mlx-community/phi-4-4bit",
          "speed_tokens_per_sec": "40-60"
        }
      }
    ],
    "UNKNOWN": []
  },
  "statistics": {
    "total_ollama_size_gb": 131.9,
    "delete_size_gb": 105.2,
    "convert_size_gb": 18.0,
    "keep_size_gb": 6.5,
    "mlx_replacement_size_gb": 62.5,
    "space_freed_gb": 105.2,
    "net_space_change_gb": -69.4,
    "delete_count": 7,
    "convert_count": 2,
    "keep_count": 2,
    "unknown_count": 0
  }
}
